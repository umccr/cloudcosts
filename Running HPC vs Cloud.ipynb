{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "> Roman, want to field the back-of-the-envelope calculations?\n",
    "> \n",
    "A single tumor/normal sample is around 400GB of raw storage\n",
    "We expect an average of 5 samples / week for the next 12 months (but it's easy to scale up the calculations if needed)\n",
    "Data flow would be from the Cache -> S3 (~3-6 months storage period) and in parallel a copy to Glacier.\n",
    "> \n",
    "What is the storage cost per sample for the lifecycle?\n",
    "What is the cost to move a sample to NCI (data out) for processing?\n",
    "How long does it take to restore a sample from Glacier if we want to keep cost < 500 AUD?\n",
    "Storage costs on NCI are:\n",
    "> \n",
    "156\\$ / TB / year on active storage (S3 equivalent) or ~\\$30 per sample if kept for 6 months\n",
    "73\\$ / TB on (dual) tape archive or ~\\$30 per sample and year\n",
    "> \n",
    "Ignore compute for now, I don't have good numbers.\n",
    "[8:49] \n",
    "If you absolutely want to, we need machines with 4GB memory / core. A sample takes ~48h on 128 cores or ~6400 CPU hours.\n",
    "> \n",
    "[8:49] \n",
    "At \\$0.0260/CPU hour that's ~$165 AUD for the processing.\n",
    "> \n",
    "[8:50] \n",
    "But those numbers would only translate 1:1 if we could run bcbio on AWS which we can't. Any other runner will have different and likely better runtimes on AWS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regarding compute at NCI and its cost:\n",
    "\n",
    "\n",
    " ```Total Grant: 300.00 KSU\n",
    "Total Used:  200.00 KSU\n",
    "Total Avail: 100.00 KSU\n",
    "Bonus Used:  41.86 KSU```\n",
    "\n",
    "\n",
    "Going through ~100k Units a month right now or about 2600$ AUD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch S3 and EC2 pricing data from AWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted to Python 3 from: https://blog.rackspace.com/experimenting-aws-price-list-api\n",
    "import json, boto3, time, requests\n",
    "from collections import defaultdict\n",
    "\n",
    "AWS_SERVICES_IDX = 'https://pricing.us-east-1.amazonaws.com/offers/v1.0/aws/index.json'\n",
    "\n",
    "AWS_EC2_URL = 'https://pricing.us-east-1.amazonaws.com/offers/v1.0/aws/AmazonEC2/current/ap-southeast-2/index.json'\n",
    "AWS_S3_URL = 'https://pricing.us-east-1.amazonaws.com/offers/v1.0/aws/AmazonS3/current/ap-southeast-2/index.json'\n",
    "AWS_GLACIER_URL = 'https://pricing.us-east-1.amazonaws.com/offers/v1.0/aws/AmazonGlacier/current/ap-southeast-2/index.json'\n",
    "\n",
    "def read_aws_prices(service, **kwargs):\n",
    "  event = defaultdict()\n",
    "\n",
    "  if service == 's3':\n",
    "    offer = json.load(open('s3.json', 'r'))\n",
    "    prices = extract_s3_prices(offer, **kwargs)\n",
    "  elif service == 'glacier':\n",
    "    offer = json.load(open('glacier.json', 'r'))\n",
    "    prices = extract_s3_prices(offer, **kwargs)\n",
    "  elif service == 'ec2':\n",
    "    offer = json.load(open('ec2.json', 'r'))\n",
    "    prices = extract_ec2_prices(offer, **kwargs)\n",
    "\n",
    "  return prices\n",
    "\n",
    "def get_aws_prices(service):\n",
    "  event = defaultdict()\n",
    "\n",
    "  if service == 's3':\n",
    "    event['offerCode'] = 'AmazonS3'\n",
    "    offer = download_offer(event)\n",
    "    prices = extract_s3_prices(offer)\n",
    "  elif service == 'glacier':\n",
    "    event['offerCode'] = 'AmazonGlacier'\n",
    "    offer = download_offer(event)\n",
    "    prices = extract_s3_prices(offer)\n",
    "  elif service == 'ec2':\n",
    "    event['offerCode'] = 'AmazonEC2'\n",
    "    offer = download_offer(event)\n",
    "    prices = extract_ec2_prices(offer)\n",
    "\n",
    "  #upload_prices(prices)\n",
    "  return prices\n",
    "\n",
    "def download_offer(event):\n",
    "  if event['offerCode'] == 'AmazonS3':\n",
    "    URL = AWS_S3_URL\n",
    "  elif event['offerCode'] == 'AmazonEC2':\n",
    "    URL = AWS_EC2_URL\n",
    "  elif event['offerCode'] == 'AmazonGlacier':\n",
    "    URL = AWS_GLACIER_URL\n",
    "\n",
    "  response = requests.get(URL)\n",
    "  return json.loads(response.text)\n",
    "\n",
    "def filter_ec2_products(products):\n",
    "  filtered = []\n",
    "\n",
    "  # Only interested in shared tenancy, linux instances\n",
    "  for sku, product in products:\n",
    "    a = product['attributes']\n",
    "    if not ('locationType' in a and\n",
    "            'location' in a and\n",
    "            'tenancy' in a and\n",
    "            a['tenancy'] == \"Shared\" and\n",
    "            a['locationType'] == 'AWS Region' and\n",
    "            a['operatingSystem'] == 'Linux'):\n",
    "      continue\n",
    "\n",
    "    a['sku'] = sku\n",
    "    filtered.append(a)\n",
    "\n",
    "  return filtered\n",
    "\n",
    "def filter_s3_products(products, **kwargs):\n",
    "  filtered = []\n",
    "\n",
    "  for sku, product in products:\n",
    "    a = product['attributes']\n",
    "    if not ('usagetype' in a and\n",
    "            'fromLocation' in a and\n",
    "            'toLocation' in a and\n",
    "            #a['usagetype'] == kwargs['usagetype'] and\n",
    "            a['fromLocation'] == kwargs['src'] and\n",
    "            a['toLocation'] == kwargs['dst']):\n",
    "            #a['fromLocationType'] == kwargs['src']):\n",
    "            #a['fromLocation'] == 'Asia Pacific (Sydney)'):\n",
    "            #a['toLocation'] == 'Asia Pacific (Sydney)'):\n",
    "      continue\n",
    "\n",
    "    a['sku'] = sku\n",
    "    filtered.append(a)\n",
    "\n",
    "  return filtered\n",
    "\n",
    "\n",
    "def extract_ec2_prices(offer):\n",
    "  terms = offer['terms']\n",
    "  products = offer['products'].items()\n",
    "\n",
    "  instances = {}\n",
    "  for a in filter_ec2_products(products):\n",
    "    term = list(terms['OnDemand'][a['sku']].items())[0][1]\n",
    "    cost = list(term['priceDimensions'].items())[0][1]\n",
    "    cost = cost['pricePerUnit']['USD']\n",
    "\n",
    "\n",
    "    info = {\"type\" : a['instanceType'], \"vcpu\" : a['vcpu'], \n",
    "            \"memory\" : a['memory'].split(\" \")[0], \"cost\" : cost}\n",
    "\n",
    "    if not a['location'] in instances:\n",
    "      instances[a['location']] = []\n",
    "\n",
    "    instances[a['location']].append(info)\n",
    "\n",
    "  return {'created': time.strftime(\"%c\"), 'published': offer['publicationDate'], \n",
    "          'instances': instances}\n",
    "\n",
    "def extract_s3_prices(offer, **kwargs):\n",
    "  terms = offer['terms']\n",
    "  products = offer['products'].items()\n",
    "\n",
    "  info = {}\n",
    "  transfers = {}\n",
    "  for a in filter_s3_products(products, **kwargs):\n",
    "    term = list(terms['OnDemand'][a['sku']].items())[0][1]\n",
    "    cost = list(term['priceDimensions'].items())[0][1]\n",
    "    cost = cost['pricePerUnit']['USD']\n",
    "    \n",
    "    info = {\"type\": a[\"usagetype\"], \"from\": a[\"fromLocation\"], \"to\": a[\"toLocation\"], \"cost\": cost}\n",
    "    if not a['fromLocation'] in transfers:\n",
    "      transfers[a['fromLocation']] = []\n",
    "\n",
    "    transfers[a['fromLocation']].append(info)\n",
    "\n",
    "  return transfers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Premises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* All in USD\n",
    "* Hour-level granularity for time model\n",
    "* GiB-level granularity for space model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S3 and Glacier cost in dollars per GB per month\n",
    "s3_egress_unit_cost = read_aws_prices(\"s3\", usagetype='APS2-DataTransfer-Out-Bytes', src='Asia Pacific (Sydney)', dst='External')\n",
    "s3_ingress_unit_cost = read_aws_prices(\"s3\", usagetype='APS2-DataTransfer-In-Bytes', src='External', dst='Asia Pacific (Sydney)')\n",
    "\n",
    "glacier_unit_cost = read_aws_prices(\"glacier\", usagetype='APS2-DataTransfer-Out-Bytes', src='Asia Pacific (Sydney)', dst='External')\n",
    "\n",
    "#s3_egress_unit_cost\n",
    "#s3_ingress_unit_cost\n",
    "#glacier_unit_cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_rate = 5/(24*7)\n",
    "storage_retention_policy = 6*30*24 # 6 months in hours\n",
    "\n",
    "sample_size = 400"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S3 ingress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'cost': '0.0000000000',\n",
       "  'from': 'External',\n",
       "  'to': 'Asia Pacific (Sydney)',\n",
       "  'type': 'APS2-DataTransfer-In-Bytes'},\n",
       " {'cost': '0.0400000000',\n",
       "  'from': 'External',\n",
       "  'to': 'Asia Pacific (Sydney)',\n",
       "  'type': 'APS2-DataTransfer-In-ABytes-T1'},\n",
       " {'cost': '0.0800000000',\n",
       "  'from': 'External',\n",
       "  'to': 'Asia Pacific (Sydney)',\n",
       "  'type': 'APS2-DataTransfer-In-ABytes-T2'},\n",
       " {'cost': '0.0000000000',\n",
       "  'from': 'External',\n",
       "  'to': 'Asia Pacific (Sydney)',\n",
       "  'type': 'APS2-DataTransfer-In-ABytes'}]"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3_ingress_unit_cost['External']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32.0"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cost of sending a single sample_size sample to S3\n",
    "s3_ingress_unit_cost = s3_ingress_unit_cost['External'][2] # assume worst rate for S3\n",
    "float(s3_ingress_unit_cost['cost']) * sample_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "640.0"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Weekly sample cost (times 5 samples per week) times 4 weeks a month\n",
    "samples_weekly_cost = float(s3_ingress_unit_cost['cost']) * sample_size * 4 * 5\n",
    "samples_weekly_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7680.0"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Yearly\n",
    "float(s3_ingress_unit_cost['cost']) * sample_size * 4 * 5 * 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S3 egress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \"What is the cost to move a sample to NCI (data out) for processing?... Ideally cost to transfer one patient sample out of S3. All we need for now.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'cost': '0.0400000000',\n",
       "  'from': 'Asia Pacific (Sydney)',\n",
       "  'to': 'External',\n",
       "  'type': 'APS2-DataTransfer-Out-ABytes'},\n",
       " {'cost': '0.0400000000',\n",
       "  'from': 'Asia Pacific (Sydney)',\n",
       "  'to': 'External',\n",
       "  'type': 'APS2-DataTransfer-Out-ABytes-T1'},\n",
       " {'cost': '0.0400000000',\n",
       "  'from': 'Asia Pacific (Sydney)',\n",
       "  'to': 'External',\n",
       "  'type': 'APS2-DataTransfer-Out-ABytes-T2'},\n",
       " {'cost': '0.1400000000',\n",
       "  'from': 'Asia Pacific (Sydney)',\n",
       "  'to': 'External',\n",
       "  'type': 'APS2-DataTransfer-Out-Bytes'}]"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3_egress_unit_cost['Asia Pacific (Sydney)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.0"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3_egress_unit_cost = s3_egress_unit_cost['Asia Pacific (Sydney)'][2]\n",
    "float(s3_egress_unit_cost['cost']) * sample_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "320.0"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Weekly sample cost (times 5 samples per week) times 4 weeks a month\n",
    "samples_weekly_cost = float(s3_egress_unit_cost['cost']) * sample_size * 4 * 5\n",
    "samples_weekly_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3840.0"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Yearly\n",
    "float(s3_egress_unit_cost['cost']) * sample_size * 4 * 5 * 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \"What is the storage cost per sample for the lifecycle?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It depends. Let's first assume that we are not in a rush to retrieve the data so that we don't go Glacier \"expedited mode\" (expensive, urgent retrieval)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'cost': '0.1400000000',\n",
       "  'from': 'Asia Pacific (Sydney)',\n",
       "  'to': 'External',\n",
       "  'type': 'APS2-DataTransfer-Out-Bytes'}]"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glacier_unit_cost['Asia Pacific (Sydney)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56.00000000000001"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(glacier_unit_cost['Asia Pacific (Sydney)'][0]['cost']) * sample_size"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
